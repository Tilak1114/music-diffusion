{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "from clap_metric import ClapMetric\n",
    "from tqdm import tqdm\n",
    "from frechet_audio_distance import FrechetAudioDistance\n",
    "\n",
    "generated_dir = '/data/tilak/projects/music-diffusion/samples/generated'\n",
    "audioldm_gen_dir = '/data/tilak/projects/music-diffusion/samples/audioldm_generated'\n",
    "ground_truth_dir = '/data/tilak/projects/music-diffusion/samples/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fad(background_dir: str, eval_dir: str) -> float:\n",
    "    frechet = FrechetAudioDistance(\n",
    "\t\t\tmodel_name=\"vggish\",\n",
    "\t\t\tuse_pca=False,\n",
    "\t\t\tuse_activation=False,\n",
    "\t\t\tverbose=False\n",
    "\t\t)\n",
    "    fad_score = frechet.score(\n",
    "        background_dir=background_dir,\n",
    "        eval_dir=eval_dir\n",
    "    )\n",
    "    return fad_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    features = {\n",
    "        'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr),\n",
    "        'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr),\n",
    "        'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr),\n",
    "        'chroma': librosa.feature.chroma_stft(y=y, sr=sr),\n",
    "        # 'tempo': librosa.feature.rhythm.tempo(y=y, sr=sr)[0]\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/easgrad/tilaksha/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6601310782322649"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fad_score = fad(generated_dir, ground_truth_dir)\n",
    "fad_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/easgrad/tilaksha/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.878403969127884"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fad_score_audio_ldm = fad(audioldm_gen_dir, ground_truth_dir)\n",
    "fad_score_audio_ldm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tilak/miniconda3/miniconda/envs/tilakenv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model clap score 0.7329609990119934\n",
      "AudioLdm clap score 0.575214684009552\n"
     ]
    }
   ],
   "source": [
    "clap_metric = ClapMetric()\n",
    "\n",
    "mymodel_clapscore = clap_metric.get_similarity(\n",
    "\t\t\t\t\tground_truth_dir=ground_truth_dir, generated_dir=generated_dir\n",
    "\t\t\t\t\t)\n",
    "audioldm_clapscore = clap_metric.get_similarity(\n",
    "\t\t\t\t\tground_truth_dir=ground_truth_dir, generated_dir=audioldm_gen_dir\n",
    "\t\t\t\t\t)\n",
    "print(\"My model clap score\", mymodel_clapscore)\n",
    "print(\"AudioLdm clap score\", audioldm_clapscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilakenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
